# abnormal-detection-using-NN
期末课程作业，基于Tensorflow神经网络对数据集进行二分类，包含特征工程，训练，测试。


# 数据处理部分

数据用了为1.4G的20003001#2017-03.csv，使用了pandas等工具包，由于数据量较大，使用迭代器读取数据块，再进行合并，下面写了两个用于整合所有数据文件的脚本。

再进一步的查看原始数据集，发现其中很多空值，同时有很多始终是一个值的属性，进行初步的筛选删除。

查看数据集格式，数据共有2337218条，过滤后106个属性，数据标签为WT_Faultcode，其中0代表正常，代表发生异常的值除了1之外还有很多，如657，287，886等。

修正标签，故障为1，非故障为0，同时去除时间属性（对分类预测无帮助），将部分属性中为空的值填为0。

删除在200w+的数据集中，变化极小的属性，以100为阈值。

筛选过后得到64个属性，接下来我们需要用到XGBoost对属性与标签的联系进行判断，XGBoost中有对属性的作用大小进行量化的函数。
我们调整合适的参数，对数据和标签进行拟合，

选出Feature importance（F score)在60以上的属性。

最终得到了28个强相关的属性值，然后我们对这28个属性进行min-max归一化，并用pickle进行保存，用来作为神经网络部分的输入。

# 神经网络的训练

使用了4层的全连接网络，利用了tensorflow作为框架，其中神经网络的超参数如下：

学习率：0.005（经过调参从0.1-》0.01-》0.005），保证了模型在快速训练时仍然能够迅速收敛

Batch：128

训练集大小：1869824 占0.8

测试集：467457 占0.2

模型的loss使用了sparse_softmax_cross_entropy作为目标函数，训练时利用tensorboard记录了loss和accuracy的变化曲线如下：

利用GPU进行加速训练，将训练集分批训练了30轮约1小时左右，loss值收敛至0.03左右，accuracy达到0.986+。

# 神经网络的测试

将保存好的网络进行restore，导入测试集数据，并使用了sklearn中的accuracy，F1_score，AUC作为模型的评价标准，并画出了ROC曲线图。

最终得到:

Loss: 0.03590356931090355

Accuarcy: 0.984785795211792 

AUC : 0.9847344612110756 

F1-Score : 0.9716060620578418
